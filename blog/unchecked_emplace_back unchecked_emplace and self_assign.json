{"metadata":{"title":"unchecked_emplace_back, unchecked_emplace and self_assign","date":"Aug 19, 2021","excerpt":"A quick std-proposal"},"content":"<p>Authors:\nAlexander Anderson</p>\n<h2>Abstract</h2>\n<h3>1. Revision History</h3>\n<ol start=\"0\">\n<li>Initial Draft</li>\n</ol>\n<p><code>unchecked_emplace_back</code> and <code>unchecked_emplace</code> are variations of two functions which already exist in the standard for several containers. The key difference being these <code>unchecked_</code> variants do not / will not allocate, they assume the capacity of already allocated storage is at least 1 more than the current size. For the purposes of this paper we can consider the signatures to <code>unchecked_emplace_back</code> and <code>unchecked_emplace</code> match those of their \"checked\" counterparts. The most relevant container is <code>vector</code>, for the purpose of this proposal consider the proposal to add these functions to all containers which function similarly to <code>vector</code>. Assume the worst of these functions in terms of safety, they can and will corrupt data, reach and dereference memory out of bounds and are the essence of running with scissors.</p>\n<pre><code class=\"hljs language-c++\"><span class=\"hljs-comment\">//...imagine somewhere buried in MSVC's vector standard header</span>\n<span class=\"hljs-keyword\">template</span> &#x3C;class... _Valty>\n<span class=\"hljs-function\">_CONSTEXPR20_CONTAINER <span class=\"hljs-keyword\">decltype</span>(<span class=\"hljs-keyword\">auto</span>) <span class=\"hljs-title\">unchecked_emplace_back</span><span class=\"hljs-params\">(_Valty &#x26;&#x26;..._Val)</span> </span>{\n  <span class=\"hljs-keyword\">return</span> _Emplace_back_with_unused_capacity(_STD forward&#x3C;_Valty>(_Val)...);\n}\n</code></pre>\n<p><code>self_assign</code> is a new function, which is similar to <code>assign</code>, like the above <code>unchecked_</code> functions, <code>self_assign</code> will not allocate. It still \"replaces\" the containers contents, however <code>self_assign</code> is much more restricted in usage.</p>\n<pre><code class=\"hljs language-c++\"><span class=\"hljs-comment\">//...imagine somewhere buried in MSVC's vector standard header</span>\n<span class=\"hljs-keyword\">template</span> &#x3C;<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> _<span class=\"hljs-title\">Iter</span>></span>\n_CONSTEXPR20_CONTAINER <span class=\"hljs-keyword\">void</span> _Self_Assign(_Iter _Last) {\n  <span class=\"hljs-keyword\">auto</span> &#x26;   _My_data = _Mypair._Myval2;\n  pointer &#x26;_Mylast  = _My_data._Mylast;\n  pointer &#x26;_Myend   = _My_data._Myend;\n\n  _Adl_verify_range(_Last, _My_data._Myend);\n  _Mylast = _Last;\n}\n\n<span class=\"hljs-keyword\">template</span> &#x3C;<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> _<span class=\"hljs-title\">Iter</span>, <span class=\"hljs-title\">enable_if_t</span>&#x3C;</span>_Is_iterator_v&#x3C;_Iter>, <span class=\"hljs-keyword\">int</span>> = <span class=\"hljs-number\">0</span>>\n_CONSTEXPR20_CONTAINER <span class=\"hljs-keyword\">void</span> <span class=\"hljs-built_in\">self_assign</span>(_Iter _Last) {\n  _Self_Assign(_Last);\n}\n</code></pre>\n<pre><code class=\"hljs language-c++\"><span class=\"hljs-comment\">//...perhaps written a bit more human like</span>\n<span class=\"hljs-comment\">//...assuming our container's implementation of vector stores three iterators _begin, _end, and _capacity</span>\n<span class=\"hljs-comment\">//where size() returns _end - _begin, capacity() returns _capacity and data() and begin() return _begin</span>\n<span class=\"hljs-keyword\">template</span> &#x3C;<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Iterator</span>, <span class=\"hljs-title\">enable_if_t</span>&#x3C;</span>_Is_iterator_v&#x3C;Iterator>, <span class=\"hljs-keyword\">int</span>> = <span class=\"hljs-number\">0</span>>\n<span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-built_in\">self_assign</span>(Iterator last) {\n    <span class=\"hljs-built_in\">assert</span>(last >= <span class=\"hljs-built_in\">begin</span>() &#x26;&#x26; last &#x3C;= (<span class=\"hljs-built_in\">begin</span>()+<span class=\"hljs-built_in\">capcity</span>()));\n    _end = last;\n}\n</code></pre>\n<p>This example hopefully gives away the rough purpose and usage of <code>self_assign</code>, it is a single parameter function which takes an iterator to the new end of the array. It assumes the memory is already managed, no lifetime management of the data is performed, if <code>self_assign</code> were used to expand the container it will be the responsibility of the maintainer to construct data otherwise if <code>self_assign</code> were used to shrink the container the maintainer is expected to have destroyed data as needed. It also expects the iterator to be within the existing bounds between <code>begin()</code> and <code>begin()+capacity()</code>, this may be (and should be) asserted. It's also a good idea to limit the function to only be enabled if the input type is in fact an iterator.</p>\n<h3>2. Motivation</h3>\n<p><code>unchecked_emplace_back</code> and <code>unchecked_emplace</code> to a certain degree already exist in most standard library implementations, with these the goal is more or less to present more of the internal utilities already written with performance in mind to the user and to prevent unnecessary workarounds to get to the same performance as the backend has available. Consider below:</p>\n<pre><code class=\"hljs language-c++\">std::vector&#x3C;<span class=\"hljs-keyword\">char</span>> a_pseudo_string;\na_pseudo_string.<span class=\"hljs-built_in\">reserve</span>(<span class=\"hljs-number\">32</span>);\n<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; <span class=\"hljs-number\">32</span>; i++) {\n  a_pseudo_string.<span class=\"hljs-built_in\">emplace_back</span>(i+<span class=\"hljs-number\">32</span>);\n}\n</code></pre>\n<p>While <code>std::vector&#x3C;char></code> is not <code>std::string</code> and this small snippet is not slow by any stretch of the imagination, parts of this snippet may be relying on some compiler optimizations to kick in. If we're lucky the compiler might notice what we do intuitively in this example which is that we don't need <code>emplace_back</code> to check on the capacity of the vector, even better and more likely is that the compiler will remove the allocation entirely given how many constants are given like this. However the key concept here is that we know, or rather have written a loop to fill our container with data we need, and we don't need to check our container's <code>capacity()</code>.</p>\n<pre><code class=\"hljs language-c++\">std::vector&#x3C;<span class=\"hljs-keyword\">char</span>> a_pseudo_string;\na_pseudo_string.<span class=\"hljs-built_in\">reserve</span>(<span class=\"hljs-number\">32</span>);\n<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; <span class=\"hljs-number\">32</span>; i++) {\n  <span class=\"hljs-comment\">//does what it says on the tin</span>\n  a_pseudo_string.<span class=\"hljs-built_in\">unchecked_emplace_back</span>(i+<span class=\"hljs-number\">32</span>);\n}\n</code></pre>\n<p>We can also roughly imagine similar benefits for calls to <code>emplace</code>, which is the backbone for <code>insert</code>.</p>\n<h3>2.1 Current state of affairs</h3>\n<p>Here is where things become painful, <code>std::vector</code> is pretty well guarded in that while we may absolutely abuse the access to <code>data()</code> to manipulate any number of indicies, there is no nice way of controlling <code>size()</code>. This makes for an awkwardly lobsided api for anyone wanting or needing to etch out the last bit of performance and try for lower level access. There are no public methods with which we can modify the internals of the container without avoiding unnecessary bounds checking, unnecessary copies, unnecessary construction or destruction calls. If we need to change the <code>size()</code> in order to maintain the validity of the vector after our manipulations, we must pay a higher level cost which may defeat the purpose.</p>\n<p>Obviously this is no accident, a well designed api for a class after all should be constrained so that misuse and errors can be handled well. However if we were aiming for safety through and through, we likely shouldn't have <code>operator[]</code> nor <code>data()</code> while we have <code>at()</code>. This paper ideally lends out a hand to all those who work at the lower level so that we don't have to write our own <code>std::vector</code> or similar just to scrape a few % points that are clearly available, or to those who're still very much in love with c and are not afraid of pointer dereferences or array access.</p>\n<h3>2.2 The assign approach</h3>\n<p>Lets consider what it currently looks like if we wanted to do something similar to <code>unchecked_emplace_back</code>.</p>\n<pre><code class=\"hljs language-c++\">std::vector&#x3C;<span class=\"hljs-keyword\">char</span>> a_pseudo_string;\na_pseudo_string.<span class=\"hljs-built_in\">reserve</span>(<span class=\"hljs-number\">32</span>);\n\n<span class=\"hljs-keyword\">char</span> *danger_ptr = a_pseudo_string.<span class=\"hljs-built_in\">data</span>();\n<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; <span class=\"hljs-number\">32</span>; i++) {\n  danger_ptr[i] = i+<span class=\"hljs-number\">32</span>;\n}\n<span class=\"hljs-comment\">// an incredibly awkward use of assign</span>\na_psudo_string.<span class=\"hljs-built_in\">assign</span>(danger_ptr, danger_ptr+<span class=\"hljs-number\">32</span>);\n</code></pre>\n<p>Depending on the datatypes we're using <code>assign</code> can be extremely penalizing as it can do a full gambit of additional work. Here at least with a bit of trivial data it's not so bad, but anything complex we will end up paying for. <code>assign</code> is designed towards assigning data as quick as humanly possible, an implementation might make self assignment a specialized case to do as little work as possible, however much like the <code>unchecked_</code> variations above we can avoid a branch because we know a bit more about the problem.</p>\n<p>When I originally was motivated to modify <code>&#x3C;vector></code> bizzarely it was because I wrote something like the above, but didn't consider anything about <code>assign</code>. I immediately was drawn to the idea of <code>unchecked_emplace_back</code> because I knew it already existed and wouldn't take much work, and my code was absolutely strewn with <code>emplace_back</code>. However as shown above, <code>self_assign</code> also did not take much work. As a bonus it also has a nice looking pattern:</p>\n<pre><code class=\"hljs language-c++\">std::vector&#x3C;some_type> buffer;\nbuffer.<span class=\"hljs-built_in\">reserve</span>(maximum_width);\n<span class=\"hljs-keyword\">size_t</span> count = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; maximum_width; i++) {\n  <span class=\"hljs-comment\">//etc...</span>\n}\nbuffer.<span class=\"hljs-built_in\">self_assign</span>(buffer.<span class=\"hljs-built_in\">data</span>()+count);\n</code></pre>\n<p>Here, <code>reserve()</code> and <code>self_assign()</code> form their own neatly enclosed block. It can be even better, because in a real example even if we're appending conditionally we can still take advantage of a branchless loop:</p>\n<pre><code class=\"hljs language-c++\">std::vector&#x3C;<span class=\"hljs-keyword\">size_t</span>> buffer;\nbuffer.<span class=\"hljs-built_in\">reserve</span>(maximum_width);\n<span class=\"hljs-keyword\">size_t</span> count = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-comment\">//a loop to store odd numbers</span>\n<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; maximum_width; i++) {\n  <span class=\"hljs-comment\">//no ifs required, no branches</span>\n  <span class=\"hljs-keyword\">bool</span> is_odd = i % <span class=\"hljs-number\">2</span>;\n  buffer.<span class=\"hljs-built_in\">data</span>()[count] = i;\n  count += is_odd;\n}\nbuffer.<span class=\"hljs-built_in\">self_assign</span>(buffer.<span class=\"hljs-built_in\">data</span>()+count);\n</code></pre>\n<p>Here we can get something out of <code>self_assign</code> we currently can't out of <code>emplace_back</code> or similar, of course the benefit is solely because we've already saved ourselves a branch and avoided any allocation. If we have to pay for a branch because we have an unknown <code>capacity()</code> requirement, we should be using <code>emplace_back</code>.</p>\n<h3>3. Considerations</h3>\n<p>All of these functions likely violate some degree of safety which the api has been striving to achieve, namely that they don't just \"work\". There are specific conditions to their use and they operate in tandem with a well placed <code>reserve()</code>. As someone explained (and I'll need help to cite who because I can't remember) there's an additional difficulty in managing pairs of things. However c and c++ are littered with examples, <code>malloc</code> and <code>free</code>, <code>new</code> and <code>delete</code> and I'm sure a number of others which I also can't remember from the talk. This makes them error prone and are the source of many existing security concerns. In very weird applications the management of these pairs is almost given up entirely, namely in compilers like DMD where the program is simply not meant to be executing for long.</p>\n<p>That said these functions are far much more like <code>malloc</code> and <code>free</code>, <code>new</code> and <code>delete</code> in that while they may be \"new\" to the publicly facing api, <code>unchecked_emplace_back</code> and <code>unchecked_emplace</code> are very much not new, especially to library implementers, nor to anyone who has peaked at a <code>&#x3C;vector></code> header. These utility functions have be lying in the background optimizing edge cases in much the way we might expect.</p>\n<p>Of the functions presented <code>self_assign</code> is very much an explicit deviation from the safety oriented api, namely it does obfuscate its ability to modify <code>size()</code>, although I very much think <code>modify_size()</code> would be far more egregious. I would fully expect that <code>self_assign</code> come with assertions for anyone safety conscious. Unlike the <code>unchecked_</code> variations it does in fact provide a new form of functionality, namely that it allows for more complicated (and performant) appends. I don't imagine it would be long for someone to use it for more complicated transformations as well.</p>\n<h3>4. Real World</h3>\n<p>Wouldn't be too convincing without numbers here's a few quick runs with a benchmark of the earlier examples:</p>\n<pre><code class=\"hljs language-txt\">| MSVC x64 debug\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|               91.60 |       10,917,030.57 |    0.5% |      0.00 | `emplace_back`\n|               31.82 |       31,421,838.18 |    0.4% |      0.00 | `unchecked_emplace_back`\n|                9.04 |      110,663,983.90 |    3.4% |      0.00 | `assign`\n|                8.65 |      115,606,936.42 |    0.1% |      0.00 | `self_assign`\n\n| MSVC x64 release\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                0.97 |    1,026,392,961.88 |    0.1% |      0.00 | `emplace_back`\n|                0.89 |    1,126,637,554.59 |    0.1% |      0.00 | `unchecked_emplace_back`\n|                0.57 |    1,741,245,136.19 |    0.1% |      0.00 | `assign`\n|                0.53 |    1,899,335,232.67 |    0.0% |      0.00 | `self_assign`\n\n| Clang x64 debug\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|               21.06 |       47,483,380.82 |    0.1% |      0.00 | `emplace_back`\n|               20.40 |       49,019,607.84 |    0.1% |      0.00 | `unchecked_emplace_back`\n|                2.78 |      359,640,359.64 |    0.1% |      0.00 | `assign`\n|                2.71 |      369,290,573.37 |    0.0% |      0.00 | `self_assign`\n\n| Clang x64 release\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                1.77 |      564,440,263.41 |    0.1% |      0.00 | `emplace_back`\n|                0.80 |    1,256,544,502.62 |    0.2% |      0.00 | `unchecked_emplace_back`\n|                0.55 |    1,803,127,874.89 |    0.0% |      0.00 | `assign`\n|                0.53 |    1,873,767,258.38 |    0.0% |      0.00 | `self_assign`\n</code></pre>\n<p>and the code, in the event I've butchered the benchmark. op should roughly translate to the cost of the write of an <code>unsigned int</code>. Strangely enough, and bit of a teaching moment, the assign pattern is the way to go (in debug or release).</p>\n<pre><code class=\"hljs language-c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">\"vector.h\"</span></span>\n\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> ANKERL_NANOBENCH_IMPLEMENT</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">\"nanobench.h\"</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">undef</span> ANKERL_NANOBENCH_IMPLEMENT</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span>\n</span>{\n  ankerl::nanobench::Bench bench;\n  \n  <span class=\"hljs-keyword\">size_t</span> count = <span class=\"hljs-number\">0</span>;\n  <span class=\"hljs-comment\">//to force the compiler to avoid optimizing anything, this should be randomized at runtime</span>\n  <span class=\"hljs-keyword\">size_t</span> batch = <span class=\"hljs-number\">1000</span>;\n  \n  bench.<span class=\"hljs-built_in\">batch</span>(batch);\n\n  <span class=\"hljs-comment\">//increase above 100 ms for more stable results, the performance benefits here are small enough</span>\n  <span class=\"hljs-comment\">//that cold runs vary a bit</span>\n  <span class=\"hljs-comment\">//bench.minEpochTime(std::chrono::seconds{ 1 });</span>\n  \n  std::vector&#x3C;<span class=\"hljs-keyword\">uint32_t</span>> buffer;\n  buffer.<span class=\"hljs-built_in\">reserve</span>(batch);\n  \n  bench.<span class=\"hljs-built_in\">run</span>(<span class=\"hljs-string\">\"emplace_back\"</span>, [&#x26;buffer, &#x26;count, &#x26;batch]() {\n    buffer.<span class=\"hljs-built_in\">clear</span>();\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; batch; i++) {\n      <span class=\"hljs-keyword\">if</span> (i % <span class=\"hljs-number\">2</span>) {\n        buffer.<span class=\"hljs-built_in\">emplace_back</span>(i);\n      }\n    }\n    count += buffer.<span class=\"hljs-built_in\">size</span>();\n  });\n  \n  \n  bench.<span class=\"hljs-built_in\">run</span>(<span class=\"hljs-string\">\"unchecked_emplace_back\"</span>, [&#x26;buffer, &#x26;count, &#x26;batch]() {\n    buffer.<span class=\"hljs-built_in\">clear</span>();\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; batch; i++) {\n      <span class=\"hljs-keyword\">if</span> (i % <span class=\"hljs-number\">2</span>) {\n        buffer.<span class=\"hljs-built_in\">unchecked_emplace_back</span>(i);\n      }\n    }\n    count += buffer.<span class=\"hljs-built_in\">size</span>();\n  });\n  \n  bench.<span class=\"hljs-built_in\">run</span>(<span class=\"hljs-string\">\"assign\"</span>, [&#x26;buffer, &#x26;count, &#x26;batch]() {\n    buffer.<span class=\"hljs-built_in\">clear</span>();\n    <span class=\"hljs-keyword\">uint32_t</span>* ptr = buffer.<span class=\"hljs-built_in\">data</span>();\n    <span class=\"hljs-keyword\">size_t</span> current = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; batch; i++) {\n      ptr[current] = i;\n      current += (i % <span class=\"hljs-number\">2</span>);\n    }\n    buffer.<span class=\"hljs-built_in\">assign</span>(buffer.<span class=\"hljs-built_in\">data</span>(), buffer.<span class=\"hljs-built_in\">data</span>() + current);\n    count += buffer.<span class=\"hljs-built_in\">size</span>();\n  });\n  \n  bench.<span class=\"hljs-built_in\">run</span>(<span class=\"hljs-string\">\"self_assign\"</span>, [&#x26;buffer, &#x26;count, &#x26;batch]() {\n    buffer.<span class=\"hljs-built_in\">clear</span>();\n    <span class=\"hljs-keyword\">uint32_t</span>* ptr = buffer.<span class=\"hljs-built_in\">data</span>();\n    <span class=\"hljs-keyword\">size_t</span> current = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &#x3C; batch; i++) {\n      ptr[current] = i;\n      current += (i % <span class=\"hljs-number\">2</span>);\n    }\n    buffer.<span class=\"hljs-built_in\">self_assign</span>(buffer.<span class=\"hljs-built_in\">data</span>() + current);\n    count += buffer.<span class=\"hljs-built_in\">size</span>();\n  });\n  \n  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n}\n</code></pre>\n<p>Here are some results when we try a benchmark against 1,000,000 ints</p>\n<pre><code class=\"hljs language-txt\">| MSVC x64 release\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                0.96 |    1,045,854,271.36 |    0.1% |      0.01 | `emplace_back`\n|                0.80 |    1,251,252,505.01 |    0.1% |      0.01 | `unchecked_emplace_back`\n|                0.65 |    1,528,457,772.34 |    0.1% |      0.01 | `assign`\n|                0.47 |    2,149,774,047.77 |    0.4% |      0.01 | `self_assign`\n\n| Clang x64 release\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                1.58 |      631,572,279.23 |    0.1% |      0.02 | `emplace_back`\n|                0.80 |    1,255,035,246.73 |    0.1% |      0.01 | `unchecked_emplace_back`\n|                0.70 |    1,430,826,636.05 |    0.6% |      0.01 | `assign`\n|                0.53 |    1,883,619,875.31 |    0.3% |      0.01 | `self_assign`\n</code></pre>\n<p>Here the results are a bit more pronounced, here's some % differences between the earlier tests from Clang.</p>\n<pre><code class=\"hljs language-txt\">| Clang x64 release (1000 ints)\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                0.55 |    1,803,127,874.89 |    0.0% |      0.00 | `assign`\n|                0.53 |    1,873,767,258.38 |    0.0% |      0.00 | `self_assign`\n|--------------------:|--------------------:|--------:|----------:|:----------\n| 1,873,767,258.38 / 1,803,127,874.89 = 1.03917 | 3.917% relative speedup\n\n| Clang x64 release (1000000 ints)\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                0.70 |    1,430,826,636.05 |    0.6% |      0.01 | `assign`\n|                0.53 |    1,883,619,875.31 |    0.3% |      0.01 | `self_assign`\n|--------------------:|--------------------:|--------:|----------:|:----------\n| 1,883,619,875.31 / 1,430,826,636.05 = 1.31645 | 31.645% relative speedup\n\n| Clang x64 release (1000 ints)\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                1.77 |      564,440,263.41 |    0.1% |      0.00 | `emplace_back`\n|                0.80 |    1,256,544,502.62 |    0.2% |      0.00 | `unchecked_emplace_back`\n|--------------------:|--------------------:|--------:|----------:|:----------\n| 1,256,544,502.62 / 564,440,263.41 = 2.22617 | 122.617% relative speedup\n\n| Clang x64 release (1000000 ints)\n|               ns/op |                op/s |    err% |     total | benchmark\n|--------------------:|--------------------:|--------:|----------:|:----------\n|                1.58 |      631,572,279.23 |    0.1% |      0.02 | `emplace_back`\n|                0.80 |    1,255,035,246.73 |    0.1% |      0.01 | `unchecked_emplace_back`\n|--------------------:|--------------------:|--------:|----------:|:----------\n| 1,255,035,246.73 / 631,572,279.23 = 1.98716 | 98.716% relative speedup\n</code></pre>\n<p>Note this test when using emplace_back is awful on the branch predictor, but hopefully this illustrates the wide range of performance impact these functions may have.</p>"}